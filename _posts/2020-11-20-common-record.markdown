---
layout:     post
title:      "一个自定义Nifi组件开发日志"
subtitle:   "\"被虐的心路历程\""
date:       2020-11-20 00:28:00
author:     "Snorlaxa"
header-img: "img/2019-07-12/bg.jpg"
catalog: true
tags:
    - 日常
    - 设计
    - 开发记录
	- Nifi
---

## 事情是这样的
这两周都在对Apache Nifi的CaptureChangeMySQL组件做优化。
我们在用Nifi做数据同步的过程中，发现它的CDC组件有比较严重的OOM问题。Nifi的CDC组件启动时有两个线程在运行：Binlog监听线程和Nifi组件线程。Binlog监听用的是开源工具[mysql-binlog-connector-java](https://github.com/shyiko/mysql-binlog-connector-java)，这个工具会启动一个监听线程不断接收来自Master的Binlog事件；Nifi组件线程则是Nifi可以通过调度系统控制的线程。一个CDC组件实例在运行时，Binlog监听线程在后面不断接收数据并存入一个内存队列中，Nifi组件线程通过调用ontrigger方法不断消费队列，两个线程的关联除了这个队列，就只有一个AtomicBoolean字段了，这是在组件停止运行时控制监听线程也关闭的开关。
造成OOM的原因有几点：
1. 内存队列没有设置上限。也就是说接收到binlog数据就能存入队列，如果消费不及时就会撑爆内存；
2. 消费数据时，会把一个事务的所有事件都缓存在内存，直到Commit事件到达才会输出到下游。所以一遇到刷数据这种一个事务几十万事件的情况就会直接崩掉。
3. Nifi背压机制不能控制Binlog监听线程停止运行。在cdc组件里，只要组件不停，binlog监听线程是不会停止的。

为了解决这些问题，我们尝试基于原生cdc组件来开发一个不会OOM的自定义组件。

# 设计思路
1. CDC组件不给内存队列设置上限是有原因的，我们当时实现了阻塞队列的CDC，运行时发现阻塞时间过长后再运行会导致获取的binlog事件无法解析，要了解具体原因需要知道MySQL发送binlog事件的整个过程，等查明白了再把原因放上来。
2. 第二个设计思路是不缓存，binlog监听线程拿到数据就提交到下游队列里。由于binlog位点应该从一个事务开始处启动，所以在一个事件输出完后，会在组件状态里记录下一个要输出的事务的起始位点。这样如果组件关闭后重启，可能造成数据重复输出。另一个缺点是不受nifi背压机制的控制，只要组件在运行，有binlog事件产生就会输出到队列里。不能保证精确一次，但速度是很快的，所以后面我们打算把它作为可配置功能加到组件里。
3. 第三个思路是文件缓存，接收到一个事务的数据后缓存到文件里，当事务结束后再复制到另一个统一的日志文件里，然后组件线程通过ontrigger读取统一日志文件。这样就能控制一个事务未完成的时候，不写入日志文件，重启时不会造成重复。
我们最终选择了第三个思路，前面两个都有比较严重的缺陷，第三个文件方式，虽然要读写文件，慢是慢点，总比出问题强。

# 要考虑得挺多
1. 缓存的内容

	既然要写文件，首先考虑要存入的内容。一开始我考虑的是写原生的event事件，拿到就写进去，等组件线程读出来再做处理，这样的好处是改动不大，能尽量与原生组件的逻辑保持一致。但这直接导致了我需要考虑读和写两个场景的binlog位点、读写文件名和位置的记录，以及读写不同场景下的tableInfo、currentDatabase等信息的缓存，在组件可以灵活停止重启的情况下，保证这么多信息的正确性变得非常不容易。我在binlog位点不断出错和tableInfo日常丢失等各种痛苦里挣扎了好几天，直到同事看了我的代码，提醒我应该在拿到binlog事件时就解析好再写文件，我才开始考虑新的方法。
	确实，如果拿到事件就处理好，写入文件的只是结果，那等组件消费时逻辑就非常简单了。这一点我在一开始就考虑过，但因为原生的cdc组件解析的结果不能序列化，并且非常复杂，就放弃了。后来我发现不能缓存结果的话可以缓存生成结果的参数，等消费时取参数生成就好了。于是自定义了一个事件类记录各种参数。

2. 变长数据写文件

	采用的方法很朴实，就是先写长度，再写内容，读的时候先读出一个long类型8字节表示长度，再读这个长度的字节数解析成事件就可以。

3. 加入gitd

	gtid是下一版本1.12.0的特性，但是我们生产环境的mysql都是集群，连的智能节点，每次binlog位点一漂移就报错。模仿了新版本的实现，结合我们写文件的机制实现了gtid特性，因为底层框架已经实现了gtid，所以这个过程不是很麻烦。

4. 从小文件复制到大文件的过程中，程序崩溃了怎么办

	程序崩溃论真是噩梦。如果一个事务文件写完后复制到统一日志文件，然后程序崩溃了，binlog位点没记录上，也就是说重启nifi后state里存的还是上个事务的，但日志文件里已经有了这个事务的数据，这就数据重复了。为了避免这种情况发现，在复制文件前会记录一次统一日志文件的大小，等写完了再记一次，如果崩溃了第二次就没记到，所以还是上一次的，这时候我们只要重启时发现记录的大小比真实文件大小要小，就说明复制中断了，把文件恢复到上次大小就可以了，多余的内容删掉。【用RandomAccessFile的setLength即可】

# 结果
目前已经能正常运行了，20万事件的大事务无压力，gtid特性也不错。